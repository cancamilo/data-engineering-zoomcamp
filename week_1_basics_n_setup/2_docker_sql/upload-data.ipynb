{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d7e4358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05dd7e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1d1f971",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../yellow_tripdata_2019-01.csv', nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9e76d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f84ca922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "339a5c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "791b0846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE yellow_taxi_data (\n",
      "\t\"VendorID\" BIGINT, \n",
      "\ttpep_pickup_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\ttpep_dropoff_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tpassenger_count BIGINT, \n",
      "\ttrip_distance FLOAT(53), \n",
      "\t\"RatecodeID\" BIGINT, \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"PULocationID\" BIGINT, \n",
      "\t\"DOLocationID\" BIGINT, \n",
      "\tpayment_type BIGINT, \n",
      "\tfare_amount FLOAT(53), \n",
      "\textra FLOAT(53), \n",
      "\tmta_tax FLOAT(53), \n",
      "\ttip_amount FLOAT(53), \n",
      "\ttolls_amount FLOAT(53), \n",
      "\timprovement_surcharge FLOAT(53), \n",
      "\ttotal_amount FLOAT(53), \n",
      "\tcongestion_surcharge FLOAT(53)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.io.sql.get_schema(df, name='yellow_taxi_data', con=engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de7b9007",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iter = pd.read_csv('../../yellow_tripdata_2019-01.csv', iterator=True, chunksize=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80ba9bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = next(df_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ec24c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c72593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b652a771",
   "metadata": {},
   "outputs": [],
   "source": [
    "df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8252c284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(n=0).to_sql(name='yellow_taxi_data', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98959ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.55 s, sys: 498 ms, total: 6.05 s\n",
      "Wall time: 16.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time df.to_sql(name='yellow_taxi_data', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42bb09d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09cd464a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted another chunk, took 16.074 second\n",
      "inserted another chunk, took 12.711 second\n",
      "inserted another chunk, took 14.802 second\n",
      "inserted another chunk, took 13.689 second\n",
      "inserted another chunk, took 15.843 second\n",
      "inserted another chunk, took 12.374 second\n",
      "inserted another chunk, took 15.993 second\n",
      "inserted another chunk, took 16.701 second\n",
      "inserted another chunk, took 13.242 second\n",
      "inserted another chunk, took 12.489 second\n",
      "inserted another chunk, took 12.937 second\n",
      "inserted another chunk, took 12.237 second\n",
      "inserted another chunk, took 12.721 second\n",
      "inserted another chunk, took 14.232 second\n",
      "inserted another chunk, took 12.463 second\n",
      "inserted another chunk, took 13.697 second\n",
      "inserted another chunk, took 18.647 second\n",
      "inserted another chunk, took 14.766 second\n",
      "inserted another chunk, took 14.109 second\n",
      "inserted another chunk, took 17.218 second\n",
      "inserted another chunk, took 14.932 second\n",
      "inserted another chunk, took 14.107 second\n",
      "inserted another chunk, took 13.394 second\n",
      "inserted another chunk, took 16.611 second\n",
      "inserted another chunk, took 13.518 second\n",
      "inserted another chunk, took 12.537 second\n",
      "inserted another chunk, took 12.028 second\n",
      "inserted another chunk, took 15.208 second\n",
      "inserted another chunk, took 13.214 second\n",
      "inserted another chunk, took 14.083 second\n",
      "inserted another chunk, took 14.562 second\n",
      "inserted another chunk, took 12.814 second\n",
      "inserted another chunk, took 12.624 second\n",
      "inserted another chunk, took 13.148 second\n",
      "inserted another chunk, took 12.841 second\n",
      "inserted another chunk, took 14.218 second\n",
      "inserted another chunk, took 14.904 second\n",
      "inserted another chunk, took 13.107 second\n",
      "inserted another chunk, took 17.192 second\n",
      "inserted another chunk, took 17.763 second\n",
      "inserted another chunk, took 17.437 second\n",
      "inserted another chunk, took 13.067 second\n",
      "inserted another chunk, took 12.775 second\n",
      "inserted another chunk, took 16.096 second\n",
      "inserted another chunk, took 15.856 second\n",
      "inserted another chunk, took 13.314 second\n",
      "inserted another chunk, took 12.602 second\n",
      "inserted another chunk, took 15.894 second\n",
      "inserted another chunk, took 16.315 second\n",
      "inserted another chunk, took 16.825 second\n",
      "inserted another chunk, took 16.094 second\n",
      "inserted another chunk, took 16.678 second\n",
      "inserted another chunk, took 16.755 second\n",
      "inserted another chunk, took 18.516 second\n",
      "inserted another chunk, took 15.081 second\n",
      "inserted another chunk, took 14.134 second\n",
      "inserted another chunk, took 13.795 second\n",
      "inserted another chunk, took 13.322 second\n",
      "inserted another chunk, took 13.104 second\n",
      "inserted another chunk, took 13.041 second\n",
      "inserted another chunk, took 15.614 second\n",
      "inserted another chunk, took 13.472 second\n",
      "inserted another chunk, took 14.089 second\n",
      "inserted another chunk, took 13.303 second\n",
      "inserted another chunk, took 13.315 second\n",
      "inserted another chunk, took 13.311 second\n",
      "inserted another chunk, took 13.234 second\n",
      "inserted another chunk, took 13.062 second\n",
      "inserted another chunk, took 13.269 second\n",
      "inserted another chunk, took 13.206 second\n",
      "inserted another chunk, took 14.771 second\n",
      "inserted another chunk, took 16.208 second\n",
      "inserted another chunk, took 17.235 second\n",
      "inserted another chunk, took 15.617 second\n",
      "inserted another chunk, took 16.338 second\n",
      "inserted another chunk, took 10.392 second\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m: \n\u001b[1;32m      2\u001b[0m     t_start \u001b[39m=\u001b[39m time()\n\u001b[0;32m----> 4\u001b[0m     df \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(df_iter)\n\u001b[1;32m      6\u001b[0m     df\u001b[39m.\u001b[39mtpep_pickup_datetime \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df\u001b[39m.\u001b[39mtpep_pickup_datetime)\n\u001b[1;32m      7\u001b[0m     df\u001b[39m.\u001b[39mtpep_dropoff_datetime \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df\u001b[39m.\u001b[39mtpep_dropoff_datetime)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/data-engineering-zoomcamp-3vTVmk8p-py3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1698\u001b[0m, in \u001b[0;36mTextFileReader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1696\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m   1697\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1698\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_chunk()\n\u001b[1;32m   1699\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m   1700\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/data-engineering-zoomcamp-3vTVmk8p-py3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1810\u001b[0m, in \u001b[0;36mTextFileReader.get_chunk\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m   1808\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[1;32m   1809\u001b[0m     size \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnrows \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_currow)\n\u001b[0;32m-> 1810\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nrows\u001b[39m=\u001b[39;49msize)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/data-engineering-zoomcamp-3vTVmk8p-py3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1771\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[1;32m   1772\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1773\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m     (\n\u001b[1;32m   1775\u001b[0m         index,\n\u001b[1;32m   1776\u001b[0m         columns,\n\u001b[1;32m   1777\u001b[0m         col_dict,\n\u001b[0;32m-> 1778\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1779\u001b[0m         nrows\n\u001b[1;32m   1780\u001b[0m     )\n\u001b[1;32m   1781\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1782\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/data-engineering-zoomcamp-3vTVmk8p-py3.10/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:230\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[0;32m--> 230\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[1;32m    231\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    232\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/data-engineering-zoomcamp-3vTVmk8p-py3.10/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:833\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True: \n",
    "    t_start = time()\n",
    "\n",
    "    df = next(df_iter)\n",
    "\n",
    "    df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "    df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)\n",
    "    \n",
    "    df.to_sql(name='yellow_taxi_data', con=engine, if_exists='append')\n",
    "\n",
    "    t_end = time()\n",
    "\n",
    "    print('inserted another chunk, took %.3f second' % (t_end - t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2178a11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-22 23:16:30--  https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.95.16, 52.217.164.64, 54.231.204.88, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.95.16|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12322 (12K) [application/octet-stream]\n",
      "Saving to: ‘taxi+_zone_lookup.csv’\n",
      "\n",
      "taxi+_zone_lookup.c 100%[===================>]  12,03K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-01-22 23:16:30 (66,8 MB/s) - ‘taxi+_zone_lookup.csv’ saved [12322/12322]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdefce25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = pd.read_csv('taxi+_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c99e27b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationID</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Zone</th>\n",
       "      <th>service_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LocationID        Borough                     Zone service_zone\n",
       "0           1            EWR           Newark Airport          EWR\n",
       "1           2         Queens              Jamaica Bay    Boro Zone\n",
       "2           3          Bronx  Allerton/Pelham Gardens    Boro Zone\n",
       "3           4      Manhattan            Alphabet City  Yellow Zone\n",
       "4           5  Staten Island            Arden Heights    Boro Zone"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5134c2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zones.to_sql(name='zones', con=engine, if_exists='replace')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-engineering-zoomcamp-3vTVmk8p-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "9537553f577f6bdbd86652daadb4d4002504acfb962e0cc7b268ae6e2b3fe48b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
